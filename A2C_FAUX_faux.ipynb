{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezzeddinegasmi/BreakOut_sb3_A2C/blob/main/A2C_FAUX_faux.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kzAT5Vq4oFT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa59a2a-fcb7-4890-e6c8-d57f2776eba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Collecting box2d-py\n",
            "  Using cached box2d-py-2.3.8.tar.gz (374 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: box2d-py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n",
            "Failed to build box2d-py\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (box2d-py)\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.11.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extra]) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.10)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.27.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement time (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for time\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install -r requirements.txt\n",
        "! pip install torch\n",
        "! pip install gymnasium\n",
        "! pip install box2d-py\n",
        "! pip install stable-baselines3[extra]\n",
        "! pip install wandb\n",
        "! pip install numpy\n",
        "! pip install matplotlib\n",
        "! pip install time\n",
        "! pip install seaborn\n",
        "! pip install tqdm\n",
        "! pip install pygame\n",
        "! pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip show pygame\n"
      ],
      "metadata": {
        "id": "cwzFLgXispYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5b1cbd7-17cf-49a2-feb6-0b3d47dbdcc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pygame\n",
            "Version: 2.6.1\n",
            "Summary: Python Game Development\n",
            "Home-page: https://www.pygame.org\n",
            "Author: A community project.\n",
            "Author-email: pygame@pygame.org\n",
            "License: LGPL\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: \n",
            "Required-by: dopamine_rl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Titre par défaut\n",
        "pip show -r requirements.txt\n"
      ],
      "metadata": {
        "id": "uFOZCZvVs-1I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "84fc899a-3831-4a53-adf1-abd26f26408a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-11-0f4742bd04fa>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-0f4742bd04fa>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pip show -r requirements.txt\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq9AN7KZEs2_"
      },
      "source": [
        "## Configuration for Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bl_x5UTeffM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d43a99b8-0bff-48b2-9a38-11a7a6fdeeab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium==1.0.0\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0) (0.0.4)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gymnasium\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.1.1\n",
            "    Uninstalling gymnasium-1.1.1:\n",
            "      Successfully uninstalled gymnasium-1.1.1\n",
            "Successfully installed gymnasium-1.0.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !pip install gymnasium==1.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwLhlnim9Nnc"
      },
      "source": [
        "## import module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6EqeyBNrnxPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a851a3c-c441-428d-f3a3-4eb293f190ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.11.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.27.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install stable-baselines3[extra] gymnasium wandb numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rTk_W3tpamE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bcb453c-2443-41ac-9e64-075411523c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment registered successfully.\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.envs.registration import register\n",
        "\n",
        "try:\n",
        "    register(\n",
        "        id='BreakoutNoFrameskip-v4',\n",
        "        entry_point='gymnasium.envs.atari:AtariEnv',\n",
        "        kwargs={'game': 'breakout', 'obs_type': 'rgb', 'frameskip': 1},\n",
        "        max_episode_steps=10000,\n",
        "        nondeterministic=False,\n",
        "    )\n",
        "    print(\"Environment registered successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error registering environment: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27iwzP2IcO6V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e6a85da-93a7-4221-fb22-0bd96860b560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ale-py==0.8.1\n",
            "  Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ale-py==0.8.1) (2.0.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from ale-py==0.8.1) (6.5.2)\n",
            "Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ale-py\n",
            "  Attempting uninstall: ale-py\n",
            "    Found existing installation: ale-py 0.11.0\n",
            "    Uninstalling ale-py-0.11.0:\n",
            "      Successfully uninstalled ale-py-0.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ale-py-0.8.1\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym[accept-rom-license,atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym[accept-rom-license,atari]) (3.1.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
            "Collecting autorom~=0.4.2 (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari])\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "INFO: pip is looking at multiple versions of gym[accept-rom-license,atari] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gym[accept-rom-license,atari]\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ale-py~=0.8.0 in /usr/local/lib/python3.11/dist-packages (from gym[accept-rom-license,atari]) (0.8.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from ale-py~=0.8.0->gym[accept-rom-license,atari]) (6.5.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (8.1.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (4.67.1)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gym[accept-rom-license,atari]) (2025.4.26)\n",
            "Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: gym, AutoROM.accept-rom-license\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827726 sha256=647b3d77b304db12fe96e2b26c7bf1342878de258c3b59f126e0255a49696c47\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/77/9e/9af5470201a0b0543937933ee99ba884cd237d2faefe8f4d37\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=autorom_accept_rom_license-0.6.1-py3-none-any.whl size=446711 sha256=016d585918d5dad201973cf25be080c5271378568ef228350b8e33a4aa5ce79d\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/fc/c6/8aa657c0d2089982f2dabd110efc68c61eb49831fdb7397351\n",
            "Successfully built gym AutoROM.accept-rom-license\n",
            "Installing collected packages: gym, AutoROM.accept-rom-license, autorom\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.4.2 gym-0.26.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gym"
                ]
              },
              "id": "759a7c5ae26d4d94a59066de3d6e9501"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'config'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e5f15c331dce>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install gym[accept-rom-license,atari] # Install gym[atari] and accept the ROM license'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgymnasium\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgym\u001b[0m \u001b[0;31m# Import gymnasium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;31m# Import the config module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Instead of gym.make, use make_atari_env from stable_baselines3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#! pip install atari-py\n",
        "#! pip install gym[atari,accept-rom-license]\n",
        "#! pip install --upgrade gym\n",
        "#env = make_atari_env(\"BreakoutNoFrameskip-v4\", n_envs=config.n_envs, seed=config.seed)\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "!pip install ale-py==0.8.1 # Install ale-py\n",
        "!pip install gym[accept-rom-license,atari] # Install gym[atari] and accept the ROM license\n",
        "import gymnasium as gym # Import gymnasium\n",
        "import config # Import the config module\n",
        "\n",
        "# Instead of gym.make, use make_atari_env from stable_baselines3\n",
        "#env = make_atari_env('BreakoutNoFrameskip-v4', n_envs=1, seed=0) # Assuming n_envs and seed are defined\n",
        "env = make_atari_env(\"BreakoutNoFrameskip-v4\", n_envs=config.n_envs, seed=config.seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niQPUTCaWh7E"
      },
      "outputs": [],
      "source": [
        "### Train A2C\n",
        "\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
        "from stable_baselines3.common.atari_wrappers import AtariWrapper\n",
        "import gymnasium as gym\n",
        "import torch\n",
        "import config\n",
        "import wandb\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from utils import make_env, unzip_file, CustomWandbCallback, RewardLogger\n",
        "import os\n",
        "from stable_baselines3.common.utils import get_latest_run_id\n",
        "import tensorboard as tb\n",
        "from tqdm import tqdm\n",
        "'''\n",
        "Set up the appropriate directories for logging and saving the model\n",
        "'''\n",
        "os.makedirs(config.log_dir, exist_ok=True)\n",
        "os.makedirs(config.save_path, exist_ok=True)\n",
        "\n",
        "#Create the callback that logs the mean reward of the last 100 episodes to wandb\n",
        "custom_callback = CustomWandbCallback(config.check_freq, config.save_path)\n",
        "\n",
        "\n",
        "'''\n",
        "Set up loging to wandb\n",
        "'''\n",
        "#Set wandb to log the training process\n",
        "if config.log_to_wandb:\n",
        "    wandb.init(project=config.project_train, entity = config.entity, name=config.name_train, notes=config.notes, sync_tensorboard=config.sync_tensorboard)\n",
        "    #wandb_callback is a callback that logs the training process to wandb, this is done because wandb.watch() does not work with sb3\n",
        "    wandb_callback = WandbCallback()\n",
        "\n",
        "\n",
        "'''\n",
        "Set up the environment\n",
        "'''\n",
        "# Create multiple environments and wrap them correctly\n",
        "env = make_atari_env(\"BreakoutNoFrameskip-v4\", n_envs=config.n_envs, seed=config.seed)\n",
        "env = VecFrameStack(env, n_stack=config.n_stack)\n",
        "\n",
        "'''\n",
        "Set up the model\n",
        "'''\n",
        "#Create the model with the parameters specified in config.py, go to config.py to see the meaning of each parameter in detail\n",
        "model = A2C(\n",
        "            policy = config.policy\n",
        "            , env = env\n",
        "            , verbose=config.verbose\n",
        "            , tensorboard_log=config.log_dir\n",
        "            , seed=config.seed\n",
        "            , policy_kwargs=config.policy_kwargs\n",
        "            , sde_sample_freq=config.sde_sample_freq\n",
        "            , normalize_advantage=config.normalize_advantage\n",
        "            , stats_window_size=config.stats_window_size\n",
        "            , _init_setup_model=config._init_setup_model\n",
        "            , device=config.device\n",
        "            , learning_rate=config.learning_rate\n",
        "            , n_steps=config.n_steps\n",
        "            , gamma=config.gamma\n",
        "            , gae_lambda=config.gae_lambda\n",
        "            , ent_coef=config.ent_coef\n",
        "            , vf_coef=config.vf_coef\n",
        "            , max_grad_norm=config.max_grad_norm\n",
        "            , rms_prop_eps=config.rms_prop_eps\n",
        "            , use_rms_prop=config.use_rms_prop\n",
        "            , use_sde=config.use_sde,\n",
        "            )\n",
        "\n",
        "#Load the model if config.pretrained is set to True in config.py\n",
        "if config.pretrained:\n",
        "    model = A2C.load(config.saved_model_path, env=env, verbose=config.verbose, tensorboard_log=config.log_dir)\n",
        "    #Unzip the file a2c_Breakout_1M.zip and store the unzipped files in the folder a2c_Breakout_unzipped\n",
        "    unzip_file(config.saved_model_path, config.unzip_file_path)\n",
        "    model.policy.load_state_dict(torch.load(os.path.join(config.unzip_file_path, \"policy.pth\")))\n",
        "    model.policy.optimizer.load_state_dict(torch.load(os.path.join(config.unzip_file_path, \"policy.optimizer.pth\")))\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Train the model and save it\n",
        "'''\n",
        "#model.learn will train the model for 1e6 timesteps, timestep is the number of actions taken by the agent,\n",
        "# in a game like breakout, the agent takes an action every frame, then the number of timesteps is the number of frames,\n",
        "# which is the number of frames in 1 game multiplied by the number of games played.\n",
        "#The average number of frames in 1 game is 1000, so 1e6 timesteps is 1000 games more or less.\n",
        "#log_interval is the number of timesteps between each log, in this case, the training process will be logged every 100 timesteps.\n",
        "#callback is a callback that logs the training process to wandb, this is done because wandb.watch() does not work with sb3\n",
        "\n",
        "if config.log_to_wandb:\n",
        "    model.learn(total_timesteps=config.total_timesteps, log_interval=config.log_interval, callback=[wandb_callback, custom_callback], progress_bar=True)\n",
        "else:\n",
        "    model.learn(total_timesteps=config.total_timesteps, log_interval=config.log_interval, callback=custom_callback, progress_bar=True)\n",
        "#Save the model\n",
        "model.save(config.saved_model_path[:-4]) #remove the .zip extension from the path\n",
        "\n",
        "\n",
        "'''\n",
        "Close the environment and finish the logging\n",
        "'''\n",
        "env.close()\n",
        "if config.log_to_wandb:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yfGedfaqp3J"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6YSg5W-ffM6"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from collections import deque\n",
        "from typing import Deque, Dict, List, Tupl\n",
        "import gymnasium as gym\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from IPython.display import clear_output\n",
        "from torch.distributions import Normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1MBQFoT9Nne",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "3d8e98db-7605-4dc7-8c83-2a2bc422e3f0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-201d50f7719b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0minitialize_uniformly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_w\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Initialize the weights and bias in [-init_w, init_w].\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minit_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minit_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ],
      "source": [
        "def initialize_uniformly(layer: nn.Linear, init_w: float = 3e-3):\n",
        "    \"\"\"Initialize the weights and bias in [-init_w, init_w].\"\"\"\n",
        "    layer.weight.data.uniform_(-init_w, init_w)\n",
        "    layer.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "\n",
        "class Actor(nn.Module):\n",
        "    def __init__(self, in_dim: int, out_dim: int):\n",
        "        \"\"\"Initialize.\"\"\"\n",
        "        super(Actor, self).__init__()\n",
        "\n",
        "        self.hidden1 = nn.Linear(in_dim, 128)\n",
        "        self.mu_layer = nn.Linear(128, out_dim)\n",
        "        self.log_std_layer = nn.Linear(128, out_dim)\n",
        "\n",
        "        initialize_uniformly(self.mu_layer)\n",
        "        initialize_uniformly(self.log_std_layer)\n",
        "\n",
        "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        x = F.relu(self.hidden1(state))\n",
        "\n",
        "        mu = torch.tanh(self.mu_layer(x)) * 2\n",
        "        log_std = F.softplus(self.log_std_layer(x))\n",
        "        std = torch.exp(log_std)\n",
        "\n",
        "        dist = Normal(mu, std)\n",
        "        action = dist.sample()\n",
        "\n",
        "        return action, dist\n",
        "\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, in_dim: int):\n",
        "        \"\"\"Initialize.\"\"\"\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        self.hidden1 = nn.Linear(in_dim, 128)\n",
        "        self.out = nn.Linear(128, 1)\n",
        "\n",
        "        initialize_uniformly(self.out)\n",
        "\n",
        "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        x = F.relu(self.hidden1(state))\n",
        "        value = self.out(x)\n",
        "\n",
        "        return value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do1RGiWJffM7"
      },
      "source": [
        "## GAE\n",
        "\n",
        "*GAE* help to reduce variance while maintaining a proper level of bias. By adjusting parameters $\\lambda \\in [0, 1]$ and $\\gamma \\in [0, 1]$. Please see [the paper](https://arxiv.org/pdf/1506.02438) for detailed description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueKVv6U-ffM7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "5c42b380-cc69-457b-a592-e2835fa40645"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'List' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b07f1aa7e117>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m def compute_gae(\n\u001b[1;32m      2\u001b[0m     \u001b[0mnext_value\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m ) -> List:\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"\"\"Compute gae.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnext_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'List' is not defined"
          ]
        }
      ],
      "source": [
        "def compute_gae(\n",
        "    next_value: list, rewards: list, masks: list, values: list, gamma: float, tau: float\n",
        ") -> List:\n",
        "    \"\"\"Compute gae.\"\"\"\n",
        "    values = values + [next_value]\n",
        "    gae = 0\n",
        "    returns: Deque[float] = deque()\n",
        "\n",
        "    for step in reversed(range(len(rewards))):\n",
        "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
        "        gae = delta + gamma * tau * masks[step] * gae\n",
        "        returns.appendleft(gae + values[step])\n",
        "\n",
        "    return list(returns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GP4TXOk9Nnd"
      },
      "source": [
        "## Network\n",
        "We will use two separated networks for actor and critic respectively. The actor network consists of one fully connected hidden layer with ReLU branched out two fully connected output layers for mean and standard deviation of Normal distribution. Pendulum-v0 has only one action which has a range from -2 to 2. In order to fit the range, the actor outputs the mean value that is multiplied by 2 after tanh. On the one hand, the critic network has two fully connected layers as a hidden layer (ReLU) and an output layer. One thing to note is that we initialize the last layers' weights and biases as uniformly distributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyp66H7QFegi"
      },
      "outputs": [],
      "source": [
        "#BreakOut_sb3_A2C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Vq8Nt9dF5u_"
      },
      "outputs": [],
      "source": [
        "#BreakOut_sb3_A2C/config.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_sCm9kjJyGq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from stable_baselines3.common.utils import get_latest_run_id\n",
        "import torch\n",
        "\n",
        "\n",
        "'''FILE TO STORE ALL THE CONFIGURATION VARIABLES'''\n",
        "\n",
        "#pretrained is a boolean that indicates if a pretrained model will be loaded\n",
        "pretrained = False # Set to True if you want to load a pretrained model\n",
        "\n",
        "#check_freq is the frequency at which the callback is called, in this case, the callback is called every 2000 timesteps\n",
        "check_freq = 2000\n",
        "\n",
        "#save_path is the path where the best model will be saved\n",
        "save_path = './a2c_Breakout_1M_save_path'\n",
        "\n",
        "#log_dir is the path where the logs will be saved\n",
        "log_dir = './log_dir'\n",
        "\n",
        "\n",
        "'''\n",
        "Hyperparameters of the model {learning_rate, gamma, device, n_steps, gae_lambda, ent_coef, vf_coef, max_grad_norm, rms_prop_eps, use_rms_prop, use_sde, sde_sample_freq, normalize_advantage}\n",
        "'''\n",
        "#policy is the policy of the model, in this case, the model will use a convolutional neural network\n",
        "policy = \"CnnPolicy\"\n",
        "\n",
        "#learning_rate is the learning rate of the model\n",
        "learning_rate =5e-4   #first trial: 5e-4   #second trial: 1e-4  #third trial: 1e-3  #fourth trial: 5e-5 #fifth trial: 5e-5 gamma = 0.90 #sixth trial: 1e-4 gamma = 0.90 #seventh trial: 5e-4 gamma = 0.90\n",
        "\n",
        "\n",
        "#gamma is the discount factor\n",
        "gamma = 0.99\n",
        "\n",
        "#device is the device where the model will be trained, if cuda is available, the model will be trained in the gpu, otherwise, it will be trained in the cpu\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "#n_steps is the number of steps taken by the model before updating the parameters\n",
        "n_steps = 24\n",
        "\n",
        "#gae_lambda is the lambda parameter of the generalized advantage estimation, set to 1 to disable it\n",
        "gae_lambda = 1\n",
        "\n",
        "#ent_coef is the entropy coefficient, set to 0 to disable it\n",
        "ent_coef = 0\n",
        "\n",
        "#vf_coef is the value function coefficient, If we set it to 0.5, then the value function loss will be half the policy loss\n",
        "vf_coef = 0.5\n",
        "\n",
        "#max_grad_norm is the maximum value for the gradient clipping\n",
        "max_grad_norm = 0.5\n",
        "\n",
        "#rms_prop_eps is the RMSProp optimizer epsilon parameter, which is a small value added to the denominator to avoid division by zero\n",
        "rms_prop_eps = 0.00001\n",
        "\n",
        "#use_rms_prop is a boolean that indicates if the RMSProp optimizer will be used\n",
        "use_rms_prop = True\n",
        "\n",
        "#use_sde is a boolean that indicates if the stochastic differential equation will be used\n",
        "#The stochastic differential equation is a method to add noise to the actions taken by the agent to improve exploration\n",
        "use_sde = False\n",
        "\n",
        "#sde_sample_freq is the frequency at which the noise is added to the actions. If set to -1, the noise will be added every timestep\n",
        "sde_sample_freq = -1\n",
        "\n",
        "#normalize_advantage is a boolean that indicates if the advantage will be normalized, by normalizing the advantage,\n",
        "# the variance of the advantage is reduced, this is done to improve the training process because the advantage is used to calculate the policy loss\n",
        "normalize_advantage = False\n",
        "\n",
        "#stats_window_size is the size of the window used to calculate the mean and standard deviation of the advantage\n",
        "stats_window_size = 100\n",
        "\n",
        "#tensorboard_log is the path where the tensorboard logs will be saved, in our case, the logs will be saved in the log_dir\n",
        "tensorboard_log = log_dir\n",
        "\n",
        "#policy_kwargs is a dictionary with the keyword arguments for the policy. If None, it will use the default arguments\n",
        "policy_kwargs = None\n",
        "\n",
        "#verbose is the verbosity level: 0 no output, 1 info, 2 debug\n",
        "verbose = 2\n",
        "\n",
        "#seed is the seed for the pseudo random number generator used by the model. It is set to None to use a random seed,\n",
        "# and set to 0 to use a fixed seed for reproducibility\n",
        "seed = None\n",
        "\n",
        "#_init_setup_model is a boolean that indicates if the model will be initialized after being created, set to True to initialize the model\n",
        "_init_setup_model = True\n",
        "\n",
        "#total_timesteps is the total number of timesteps that the model will be trained. In this case, the model will be trained for 1e7 timesteps\n",
        "#Take into account that the number of timesteps is not the number of episodes, in a game like breakout, the agent takes an action every frame,\n",
        "# then the number of timesteps is the number of frames, which is the number of frames in 1 game multiplied by the number of games played.\n",
        "#The average number of frames in 1 game is 1000, so 1e7 timesteps is 1000 games more or less.\n",
        "total_timesteps = int(3e7)\n",
        "\n",
        "#log_interval is the number of timesteps between each log, in this case, the training process will be logged every 100 timesteps.\n",
        "log_interval = 100\n",
        "\n",
        "'''\n",
        "Saved model path\n",
        "'''\n",
        "saved_model_path = \"./a2c_Breakout_30M_lr_5e-4_gamma_90.zip\"\n",
        "unzip_file_path = \"./a2c_Breakout_30M_lr_5e-4_gamma_90_unzipped\"\n",
        "'''\n",
        "Environment variables\n",
        "'''\n",
        "#n_stack is the number of frames stacked together to form the input to the model\n",
        "n_stack = 4\n",
        "#n_envs is the number of environments that will be run in parallel\n",
        "n_envs = 4\n",
        "\n",
        "\n",
        "'''\n",
        "Wandb configuration\n",
        "'''\n",
        "\n",
        "#log_to_wandb is a boolean that indicates if the training process will be logged to wandb\n",
        "log_to_wandb = False\n",
        "\n",
        "#project is the name of the project in wandb\n",
        "project_train = \"BREAKOUT_SB3_BENCHMARK\"\n",
        "project_test = \"breakout-a2c-test\"\n",
        "\n",
        "#entity is the name of the team in wandb\n",
        "entity = \"ai42\"\n",
        "\n",
        "#name is the name of the run in wandb\n",
        "name_train = \"a2c_breakout_lr_5e-4_gamma_90\"\n",
        "name_test = \"a2c_breakout_test\"\n",
        "#notes is a description of the run\n",
        "notes = \"a2c_breakout with parameters: {}\".format(locals()) #locals() returns a dictionary with all the local variables, in this case, all the variables in this file\n",
        "#sync_tensorboard is a boolean that indicates if the tensorboard logs will be synced to wandb\n",
        "sync_tensorboard = True\n",
        "\n",
        "\n",
        "'''\n",
        "Test configuration\n",
        "'''\n",
        "test_episodes = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5WeE0uoQqcV"
      },
      "outputs": [],
      "source": [
        "#BreakOut_sb3_A2C/train_A2C.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS1kPXyQQurM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "55371b05-43c2-4c99-e0c8-6f9791ce907f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'config'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-91153f45dfed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgymnasium\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msb3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWandbCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
        "from stable_baselines3.common.atari_wrappers import AtariWrapper\n",
        "import gymnasium as gym\n",
        "import torch\n",
        "import config\n",
        "import wandb\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from utils import make_env, unzip_file, CustomWandbCallback, RewardLogger\n",
        "import os\n",
        "from stable_baselines3.common.utils import get_latest_run_id\n",
        "import tensorboard as tb\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "'''\n",
        "Set up the appropriate directories for logging and saving the model\n",
        "'''\n",
        "os.makedirs(config.log_dir, exist_ok=True)\n",
        "os.makedirs(config.save_path, exist_ok=True)\n",
        "\n",
        "#Create the callback that logs the mean reward of the last 100 episodes to wandb\n",
        "custom_callback = CustomWandbCallback(config.check_freq, config.save_path)\n",
        "\n",
        "\n",
        "'''\n",
        "Set up loging to wandb\n",
        "'''\n",
        "#Set wandb to log the training process\n",
        "if config.log_to_wandb:\n",
        "    wandb.init(project=config.project_train, entity = config.entity, name=config.name_train, notes=config.notes, sync_tensorboard=config.sync_tensorboard)\n",
        "    #wandb_callback is a callback that logs the training process to wandb, this is done because wandb.watch() does not work with sb3\n",
        "    wandb_callback = WandbCallback()\n",
        "\n",
        "\n",
        "'''\n",
        "Set up the environment\n",
        "'''\n",
        "# Create multiple environments and wrap them correctly\n",
        "env = make_atari_env(\"BreakoutNoFrameskip-v4\", n_envs=config.n_envs, seed=config.seed)\n",
        "env = VecFrameStack(env, n_stack=config.n_stack)\n",
        "\n",
        "\n",
        "'''\n",
        "Set up the model\n",
        "'''\n",
        "#Create the model with the parameters specified in config.py, go to config.py to see the meaning of each parameter in detail\n",
        "model = A2C(\n",
        "            policy = config.policy\n",
        "            , env = env\n",
        "            , verbose=config.verbose\n",
        "            , tensorboard_log=config.log_dir\n",
        "            , seed=config.seed\n",
        "            , policy_kwargs=config.policy_kwargs\n",
        "            , sde_sample_freq=config.sde_sample_freq\n",
        "            , normalize_advantage=config.normalize_advantage\n",
        "            , stats_window_size=config.stats_window_size\n",
        "            , _init_setup_model=config._init_setup_model\n",
        "            , device=config.device\n",
        "            , learning_rate=config.learning_rate\n",
        "            , n_steps=config.n_steps\n",
        "            , gamma=config.gamma\n",
        "            , gae_lambda=config.gae_lambda\n",
        "            , ent_coef=config.ent_coef\n",
        "            , vf_coef=config.vf_coef\n",
        "            , max_grad_norm=config.max_grad_norm\n",
        "            , rms_prop_eps=config.rms_prop_eps\n",
        "            , use_rms_prop=config.use_rms_prop\n",
        "            , use_sde=config.use_sde,\n",
        "            )\n",
        "\n",
        "#Load the model if config.pretrained is set to True in config.py\n",
        "if config.pretrained:\n",
        "    model = A2C.load(config.saved_model_path, env=env, verbose=config.verbose, tensorboard_log=config.log_dir)\n",
        "    #Unzip the file a2c_Breakout_1M.zip and store the unzipped files in the folder a2c_Breakout_unzipped\n",
        "    unzip_file(config.saved_model_path, config.unzip_file_path)\n",
        "    model.policy.load_state_dict(torch.load(os.path.join(config.unzip_file_path, \"policy.pth\")))\n",
        "    model.policy.optimizer.load_state_dict(torch.load(os.path.join(config.unzip_file_path, \"policy.optimizer.pth\")))\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Train the model and save it\n",
        "'''\n",
        "#model.learn will train the model for 1e6 timesteps, timestep is the number of actions taken by the agent,\n",
        "# in a game like breakout, the agent takes an action every frame, then the number of timesteps is the number of frames,\n",
        "# which is the number of frames in 1 game multiplied by the number of games played.\n",
        "#The average number of frames in 1 game is 1000, so 1e6 timesteps is 1000 games more or less.\n",
        "#log_interval is the number of timesteps between each log, in this case, the training process will be logged every 100 timesteps.\n",
        "#callback is a callback that logs the training process to wandb, this is done because wandb.watch() does not work with sb3\n",
        "\n",
        "if config.log_to_wandb:\n",
        "    model.learn(total_timesteps=config.total_timesteps, log_interval=config.log_interval, callback=[wandb_callback, custom_callback], progress_bar=True)\n",
        "else:\n",
        "    model.learn(total_timesteps=config.total_timesteps, log_interval=config.log_interval, callback=custom_callback, progress_bar=True)\n",
        "#Save the model\n",
        "model.save(config.saved_model_path[:-4]) #remove the .zip extension from the path\n",
        "\n",
        "\n",
        "'''\n",
        "Close the environment and finish the logging\n",
        "'''\n",
        "env.close()\n",
        "if config.log_to_wandb:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiTRVsblffM7"
      },
      "source": [
        "## A2C Agent\n",
        "Here is a summary of A2CAgent class.\n",
        "\n",
        "| Method           | Note                                                 |\n",
        "|---               |---                                                   |\n",
        "|select_action     | select an action from the input state.               |\n",
        "|step              | take an action and return the response of the env.   |\n",
        "|update_model      | update the model by gradient descent.                |\n",
        "|train             | train the agent during num_frames.                   |\n",
        "|test              | test the agent (1 episode).                          |\n",
        "|_plot             | plot the training progresses.                        |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrUtbRh29Nne",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "6cd82b19-8c6b-4283-eab4-63e6e6b7fbc9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b9534543e189>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mA2CAgent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"A2CAgent interacting with environment.\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mAtribute\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopenAI\u001b[0m \u001b[0mGym\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b9534543e189>\u001b[0m in \u001b[0;36mA2CAgent\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;34m\"\"\"Select an action from the input state.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "class A2CAgent:\n",
        "    \"\"\"A2CAgent interacting with environment.\n",
        "\n",
        "    Atribute:\n",
        "        env (gym.Env): openAI Gym environment\n",
        "        gamma (float): discount factor\n",
        "        entropy_weight (float): rate of weighting entropy into the loss function\n",
        "        device (torch.device): cpu / gpu\n",
        "        actor (nn.Module): target actor model to select actions\n",
        "        critic (nn.Module): critic model to predict state values\n",
        "        actor_optimizer (optim.Optimizer) : optimizer of actor\n",
        "        critic_optimizer (optim.Optimizer) : optimizer of critic\n",
        "        transition (list): temporory storage for the recent transition\n",
        "        total_step (int): total step numbers\n",
        "        is_test (bool): flag to show the current mode (train / test)\n",
        "        seed (int): random seed\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, env: gym.Env, gamma: float, entropy_weight: float, seed: int = 777):\n",
        "        \"\"\"Initialize.\"\"\"\n",
        "        self.env = env\n",
        "        self.gamma = gamma\n",
        "        self.entropy_weight = entropy_weight\n",
        "        self.seed = seed\n",
        "\n",
        "        # device: cpu / gpu\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(self.device)\n",
        "\n",
        "        # networks\n",
        "        obs_dim = env.observation_space.shape[0]\n",
        "        action_dim = env.action_space.shape[0]\n",
        "        self.actor = Actor(obs_dim, action_dim).to(self.device)\n",
        "        self.critic = Critic(obs_dim).to(self.device)\n",
        "\n",
        "        # optimizer\n",
        "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=1e-4)\n",
        "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=1e-3)\n",
        "\n",
        "        # transition (state, log_prob, next_state, reward, done)\n",
        "        self.transition: list = list()\n",
        "\n",
        "        # total steps count\n",
        "        self.total_step = 0\n",
        "\n",
        "        # mode: train / test\n",
        "        self.is_test = False\n",
        "\n",
        "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Select an action from the input state.\"\"\"\n",
        "        state = torch.FloatTensor(state).to(self.device)\n",
        "        action, dist = self.actor(state)\n",
        "        selected_action = dist.mean if self.is_test else action\n",
        "\n",
        "        if not self.is_test:\n",
        "            log_prob = dist.log_prob(selected_action).sum(dim=-1)\n",
        "            self.transition = [state, log_prob]\n",
        "\n",
        "        return selected_action.clamp(-2.0, 2.0).cpu().detach().numpy()\n",
        "\n",
        "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
        "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
        "        next_state, reward, terminated, truncated, _ = self.env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        if not self.is_test:\n",
        "            self.transition.extend([next_state, reward, done])\n",
        "\n",
        "        return next_state, reward, done\n",
        "\n",
        "    def update_model(self) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Update the model by gradient descent.\"\"\"\n",
        "        state, log_prob, next_state, reward, done = self.transition\n",
        "\n",
        "        # Q_t   = r + gamma * V(s_{t+1})  if state != Terminal\n",
        "        #       = r                       otherwise\n",
        "        mask = 1 - done\n",
        "        next_state = torch.FloatTensor(next_state).to(self.device)\n",
        "        pred_value = self.critic(state)\n",
        "        targ_value = reward + self.gamma * self.critic(next_state) * mask\n",
        "        value_loss = F.smooth_l1_loss(pred_value, targ_value.detach())\n",
        "\n",
        "        # update value\n",
        "        self.critic_optimizer.zero_grad()\n",
        "        value_loss.backward()\n",
        "        self.critic_optimizer.step()\n",
        "\n",
        "        # advantage = Q_t - V(s_t)\n",
        "        advantage = (targ_value - pred_value).detach()  # not backpropagated\n",
        "        policy_loss = -advantage * log_prob\n",
        "        policy_loss += self.entropy_weight * -log_prob  # entropy maximization\n",
        "\n",
        "        # update policy\n",
        "        self.actor_optimizer.zero_grad()\n",
        "        policy_loss.backward()\n",
        "        self.actor_optimizer.step()\n",
        "\n",
        "        return policy_loss.item(), value_loss.item()\n",
        "\n",
        "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
        "        \"\"\"Train the agent.\"\"\"\n",
        "        self.is_test = False\n",
        "\n",
        "        actor_losses, critic_losses, scores = [], [], []\n",
        "        state, _ = self.env.reset(seed=self.seed)\n",
        "        score = 0\n",
        "\n",
        "        for self.total_step in range(1, num_frames + 1):\n",
        "            action = self.select_action(state)\n",
        "            next_state, reward, done = self.step(action)\n",
        "\n",
        "            actor_loss, critic_loss = self.update_model()\n",
        "            actor_losses.append(actor_loss)\n",
        "            critic_losses.append(critic_loss)\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "\n",
        "            # if episode ends\n",
        "            if done:\n",
        "                state, _ = self.env.reset(seed=self.seed)\n",
        "                scores.append(score)\n",
        "                score = 0\n",
        "\n",
        "            # plot\n",
        "            if self.total_step % plotting_interval == 0:\n",
        "                self._plot(self.total_step, scores, actor_losses, critic_losses)\n",
        "        self.env.close()\n",
        "\n",
        "    def test(self, video_folder: str):\n",
        "        \"\"\"Test the agent.\"\"\"\n",
        "        self.is_test = True\n",
        "\n",
        "        tmp_env = self.env\n",
        "        self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
        "\n",
        "        state, _ = self.env.reset(seed=self.seed)\n",
        "        done = False\n",
        "        score = 0\n",
        "\n",
        "        while not done:\n",
        "            action = self.select_action(state)\n",
        "            next_state, reward, done = self.step(action)\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "\n",
        "        print(\"score: \", score)\n",
        "        self.env.close()\n",
        "\n",
        "        self.env = tmp_env\n",
        "\n",
        "    def _plot(\n",
        "        self,\n",
        "        frame_idx: int,\n",
        "        scores: List[float],\n",
        "        actor_losses: List[float],\n",
        "        critic_losses: List[float],\n",
        "    ):\n",
        "        \"\"\"Plot the training progresses.\"\"\"\n",
        "\n",
        "        def subplot(loc: int, title: str, values: List[float]):\n",
        "            plt.subplot(loc)\n",
        "            plt.title(title)\n",
        "            plt.plot(values)\n",
        "\n",
        "        subplot_params = [\n",
        "            (131, f\"frame {frame_idx}. score: {np.mean(scores[-10:])}\", scores),\n",
        "            (132, \"actor_loss\", actor_losses),\n",
        "            (133, \"critic_loss\", critic_losses),\n",
        "        ]\n",
        "\n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=(30, 5))\n",
        "        for loc, title, values in subplot_params:\n",
        "            subplot(loc, title, values)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADyte0QjffM8"
      },
      "outputs": [],
      "source": [
        "def A2C_iter(\n",
        "    epoch: int,\n",
        "    mini_batch_size: int,\n",
        "    states: torch.Tensor,\n",
        "    actions: torch.Tensor,\n",
        "    values: torch.Tensor,\n",
        "    log_probs: torch.Tensor,\n",
        "    returns: torch.Tensor,\n",
        "    advantages: torch.Tensor,\n",
        "):\n",
        "    \"\"\"Yield mini-batches.\"\"\"\n",
        "    batch_size = states.size(0)\n",
        "    for _ in range(epoch):\n",
        "        for _ in range(batch_size // mini_batch_size):\n",
        "            rand_ids = np.random.choice(batch_size, mini_batch_size)\n",
        "            yield states[rand_ids, :], actions[rand_ids], values[rand_ids], log_probs[\n",
        "                rand_ids\n",
        "            ], returns[rand_ids], advantages[rand_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK9d7SBQ9Nnf"
      },
      "outputs": [],
      "source": [
        "# environment\n",
        "env = gym.make(\"Pendulum-v1\", render_mode=\"rgb_array\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q59eeKYO-FtG"
      },
      "source": [
        "## Set random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7ApXHQ7gRyA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "34a98e1b-ce2e-4853-ead2-c67f550f9c66"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'random' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-eae4d796002c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m777\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mseed_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
          ]
        }
      ],
      "source": [
        "def seed_torch(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.backends.cudnn.enabled:\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "seed = 777\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "seed_torch(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvHO1op6ffM8"
      },
      "source": [
        "## Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PQl2ZfS9Nnf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "4c0216c2-82b2-455b-f21c-2a58f809ec17"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'A2CAgent' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7b7b91d8dbdb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mentropy_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA2CAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'A2CAgent' is not defined"
          ]
        }
      ],
      "source": [
        "num_frames = 100000\n",
        "gamma = 0.90\n",
        "entropy_weight = 1e-2\n",
        "\n",
        "agent = A2CAgent(env, gamma, entropy_weight, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr5N63DL9Nng"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcSfuw9h9Nng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "53c288dd-e6cf-47ab-d308-1f423410f8c0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'agent' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4326fee8443c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
          ]
        }
      ],
      "source": [
        "agent.train(num_frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz1mY15w9Nng"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuGSvYK-9Nng"
      },
      "outputs": [],
      "source": [
        "# test\n",
        "video_folder = \"videos/a2c\"\n",
        "agent.test(video_folder=video_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfNxDFpe9Nng"
      },
      "source": [
        "## Render"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVyGhnuj9Nng"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import glob\n",
        "import io\n",
        "import os\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "\n",
        "def ipython_show_video(path: str) -> None:\n",
        "    \"\"\"Show a video at `path` within IPython Notebook.\"\"\"\n",
        "    if not os.path.isfile(path):\n",
        "        raise NameError(\"Cannot access: {}\".format(path))\n",
        "\n",
        "    video = io.open(path, \"r+b\").read()\n",
        "    encoded = base64.b64encode(video)\n",
        "\n",
        "    display(\n",
        "        HTML(\n",
        "            data=\"\"\"\n",
        "        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n",
        "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n",
        "        </video>\n",
        "        \"\"\".format(\n",
        "                encoded.decode(\"ascii\")\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def show_latest_video(video_folder: str) -> str:\n",
        "    \"\"\"Show the most recently recorded video from video folder.\"\"\"\n",
        "    list_of_f tt le rr4iles = glob.glob(os.path.join(video_folder, \"*.mp4\"))\n",
        "    latest_file = max(list_of_files, key=os.path.getctime)\n",
        "    ipython_show_video(latest_file)\n",
        "    return latest_file\n",
        "\n",
        "\n",
        "latest_file = show_latest_video(video_folder=video_folder)\n",
        "print(\"Played:\", latest_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6UWj8nyOWVz8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE21mYeT3JYJ"
      },
      "outputs": [],
      "source": [
        "def render(self, mode='human'):\n",
        "    if not hasattr(self, 'screen'):\n",
        "        import pygame\n",
        "        pygame.init()\n",
        "        self.screen = pygame.display.set_mode((self.screen_width, self.screen_height))\n",
        "        pygame.display.set_caption(\"Breakout Continuous\")\n",
        "        self.clock = pygame.time.Clock()\n",
        "\n",
        "    self.screen.fill((0, 0, 0))\n",
        "    pygame.draw.circle(self.screen, (255, 255, 255), (int(self.ball_x), int(self.ball_y)), self.ball_size)\n",
        "    pygame.draw.rect(\n",
        "        self.screen,\n",
        "        (0, 255, 0),\n",
        "        pygame.Rect(int(self.paddle_x), self.screen_height - self.paddle_height, self.paddle_width, self.paddle_height)\n",
        "    )\n",
        "\n",
        "    pygame.display.flip()\n",
        "    self.clock.tick(60)\n",
        "\n",
        "def close(self):\n",
        "    if hasattr(self, 'screen'):\n",
        "        import pygame\n",
        "        pygame.quit()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}